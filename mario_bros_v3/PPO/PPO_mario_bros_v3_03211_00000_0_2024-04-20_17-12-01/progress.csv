episode_reward_max,episode_reward_min,episode_reward_mean,episode_len_mean,episodes_this_iter,episodes_timesteps_total,num_faulty_episodes,num_healthy_workers,num_in_flight_async_reqs,num_remote_worker_restarts,num_agent_steps_sampled,num_agent_steps_trained,num_env_steps_sampled,num_env_steps_trained,num_env_steps_sampled_this_iter,num_env_steps_trained_this_iter,num_env_steps_sampled_throughput_per_sec,num_env_steps_trained_throughput_per_sec,timesteps_total,num_steps_trained_this_iter,agent_timesteps_total,done,episodes_total,training_iteration,trial_id,date,timestamp,time_this_iter_s,time_total_s,pid,hostname,node_ip,time_since_restore,iterations_since_restore,info/num_env_steps_sampled,info/num_env_steps_trained,info/num_agent_steps_sampled,info/num_agent_steps_trained,sampler_results/episode_reward_max,sampler_results/episode_reward_min,sampler_results/episode_reward_mean,sampler_results/episode_len_mean,sampler_results/episodes_this_iter,sampler_results/episodes_timesteps_total,sampler_results/num_faulty_episodes,hist_stats/episode_reward,hist_stats/episode_lengths,timers/training_iteration_time_ms,timers/restore_workers_time_ms,timers/training_step_time_ms,timers/sample_time_ms,timers/load_time_ms,timers/load_throughput,timers/learn_time_ms,timers/learn_throughput,timers/synch_weights_time_ms,counters/num_env_steps_sampled,counters/num_env_steps_trained,counters/num_agent_steps_sampled,counters/num_agent_steps_trained,perf/cpu_util_percent,perf/ram_util_percent,sampler_results/hist_stats/episode_reward,sampler_results/hist_stats/episode_lengths,info/learner/default_policy/num_agent_steps_trained,info/learner/default_policy/num_grad_updates_lifetime,info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy,info/learner/default_policy/learner_stats/allreduce_latency,info/learner/default_policy/learner_stats/grad_gnorm,info/learner/default_policy/learner_stats/cur_kl_coeff,info/learner/default_policy/learner_stats/cur_lr,info/learner/default_policy/learner_stats/total_loss,info/learner/default_policy/learner_stats/policy_loss,info/learner/default_policy/learner_stats/vf_loss,info/learner/default_policy/learner_stats/vf_explained_var,info/learner/default_policy/learner_stats/kl,info/learner/default_policy/learner_stats/entropy,info/learner/default_policy/learner_stats/entropy_coeff
nan,nan,nan,nan,0,0,0,4,0,0,1024,1024,512,512,512,512,15.586531624460655,15.586531624460655,512,512,1024,False,0,1,03211_00000,2024-04-20_17-12-42,1713651162,32.85164713859558,32.85164713859558,68982,hanaa-laptop.local,127.0.0.1,32.85164713859558,1,512,512,1024,1024,nan,nan,nan,nan,0,0,0,[],[],32848.882,0.015,32848.829,1604.683,1.491,343432.536,31233.452,16.393,8.708,512,512,1024,1024,23.21489361702128,76.0276595744681,[],[],64.0,80.5,79.5,0.0,0.236507408041507,0.19999999999999998,2e-05,-0.29584811177337544,-0.007557282969355583,7.106977641768708e-06,0.534194752573967,0.002424282210711226,2.8877745270729065,0.09999999999999999
nan,nan,nan,nan,0,0,0,4,0,0,2048,2048,1024,1024,512,512,15.21667856470008,15.21667856470008,1024,512,2048,False,0,2,03211_00000,2024-04-20_17-13-15,1713651195,33.65007305145264,66.50172019004822,68982,hanaa-laptop.local,127.0.0.1,66.50172019004822,2,1024,1024,2048,2048,nan,nan,nan,nan,0,0,0,[],[],33248.092,0.017,33248.042,1953.121,3.372,151819.275,31283.421,16.366,7.792,1024,1024,2048,2048,24.764583333333334,76.91666666666667,[],[],64.0,240.5,79.5,0.0,0.2984557527117431,0.09999999999999999,2e-05,-0.29811004153452814,-0.010259284195490182,1.2429756445619945e-05,0.49218619614839554,0.003972016009197432,2.8825105667114257,0.09999999999999999
